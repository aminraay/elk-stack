input {
  beats {
    port => 5000
  }
}

filter {
  # Create proccess.command_line
  if [process][args] {
    ruby {
      code => '
        args = event.get("[process][args]")
        if args.is_a?(Array) && !args.empty?
          event.set("[process][command_line]", args.join(" "))
        end
      '
    }
  }
  # Remove extra IP
  ruby {
    code => '
      host_ips = event.get("[host][ip]")
      if host_ips.is_a?(Array)
        filtered_ips = host_ips.select { |ip| 
          ip =~ /^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$/ &&
          !ip.start_with?("127.") &&
          !ip.start_with?("169.254.") &&
          !ip.include?(":")
        }
        event.set("[host][ip]", filtered_ips.first) if filtered_ips.any?
      end
    '
  }
  
  # Timestamp parsing
  date{
    match => ["dt", "yyyy-MM-dd HH:mm:ss", "ISO8601"]
    target => "@timestamp"
    tag_on_failure => ["date_parse_failure"]
  }

  # Add ingestion time in ECS field
  ruby {
    code => 'event.set("event.ingested", LogStash::Timestamp.new(Time.now.utc))'
  }
}

output {
  if "date_parse_failure" in [tags] {
    elasticsearch {
      hosts => ["https://elasticsearch:9200"]

      # Index configuration
      index => "log-linux-errors-%{+YYYY.MM.dd}"

      # SSL & Authentication
      ssl_enabled => true
      ssl_certificate_authorities => "/usr/share/logstash/config/certs/ca.crt"
      user => "${ELASTIC_USERNAME}"
      password => "${ELASTIC_PASSWORD}"
    }

  } else {
    elasticsearch {
      hosts => ["https://elasticsearch:9200"]

      # Stream configuration
      data_stream => true
      data_stream_type => "logs"
      data_stream_dataset => "linux"

      # SSL & Authentication
      ssl_enabled => true
      ssl_certificate_authorities => "/usr/share/logstash/config/certs/ca.crt"
      user => "${ELASTIC_USERNAME}"
      password => "${ELASTIC_PASSWORD}"
    }
  }
}